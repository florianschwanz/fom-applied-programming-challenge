{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Applied Programming Coding Challenge #2\n",
    "\n",
    "# General Information\n",
    "\n",
    "This GAN aims to generate images of Pokemon based on 801 original images of Pokemon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from IPython.display import HTML\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "```TIP FOR DEVS``` Detect whether notebook is executed in Colab or not. Use this information to load data from local directory or Google Drive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Set seed to get reproducible results\n",
    "manualSeed = 42\n",
    "# manualSeed = random.randint(1, 10000)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Configuration\n",
    "\n",
    "## 0.1 Configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    drive.mount('/content/gdrive')\n",
    "    dataroot_parent = \"/content/gdrive/My Drive/Colab Files\"\n",
    "else:\n",
    "    dataroot_parent = \"..\"\n",
    "\n",
    "dataroot = dataroot_parent + \"/data/pokemon-images\"\n",
    "workers = 2\n",
    "batch_size = 64\n",
    "image_size = 64\n",
    "color_channels = 3\n",
    "latent_vector = 128\n",
    "ngf = 64 # Size of feature maps in generator\n",
    "ndf = 64 # Size of feature maps in discriminator\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.01\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load data\n",
    "\n",
    "## 1.2 Load sprites into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define transformation pipeline\n",
    "train_dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               # transforms.Resize(image_size),\n",
    "                               # transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataloader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 Understand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display sample from first batch\n",
    "# real_batch = next(iter(dataloader))\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 Prepare net\n",
    "\n",
    "## 3.1 Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"Initializes weights based on layer type\"\"\"\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "def get_noise(batch_size=batch_size):\n",
    "    return Variable(torch.rand(batch_size, latent_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Initialize generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator net\"\"\"\n",
    "    \n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_vector, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=256 * 8 * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256 * 8 * 8),\n",
    "        )\n",
    "        self.ct1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.ct2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.ct3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.ct4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=color_channels, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.fc1(input)\n",
    "        input = self.ct1(input.view(-1, 256, 8, 8))\n",
    "        input = self.ct2(input)\n",
    "        input = self.ct3(input)\n",
    "        return self.ct4(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply weights\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Show generator\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Initialize discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator net\"\"\"\n",
    "    \n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=color_channels, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "        )\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "        )\n",
    "        self.conv3=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "        )\n",
    "        self.conv4=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.dp = nn.Dropout(0.5)\n",
    "        self.d_out = nn.Linear(512 ,1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.conv3(input)\n",
    "        input = self.conv4(input)\n",
    "        input = input.view((-1, 256, 8, 8))\n",
    "        input = self.dp(F.leaky_relu(self.fc1(input)))\n",
    "        out = self.d_out(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply weights\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Show discriminator\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4 Init loss fucolor_channelstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize binary cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, latent_vector, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta1, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta1, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def saveFileToGoogleDrive(image, fileName, dirName = \"Colab Files\"):\n",
    "    \"\"\"Saves a file to Google Drive\"\"\"\n",
    "    \n",
    "    save_image(image, '/content/gdrive/My Drive/' + dirName + '/' + fileName)\n",
    "\n",
    "def saveFileToLocal(image, fileName, dirName = \"pokemon-images\"):\n",
    "    \"\"\"Saves a file to local directory\"\"\"\n",
    "    \n",
    "    print(\"saveFileToLocal ../build/\" + dirName + '/' + fileName)\n",
    "    save_image(image, '../build/' + dirName + '/' + fileName)\n",
    "    \n",
    "def generateImage(epoch, image):\n",
    "    \"\"\"Generates an image based on a given input vector\"\"\"\n",
    "        \n",
    "    print(\"generateImage(epoch=\" + str(epoch) + \")\")\n",
    "    now = datetime.now()\n",
    "    fileName = str(now.strftime('%Y-%m-%dT%H-%M-%S')) + '_epoch_' + str(epoch) + '.png'\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        saveFileToGoogleDrive(image, fileName)\n",
    "    else:\n",
    "        saveFileToLocal(image, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "# Input vector to generate new images\n",
    "input_vector = Variable(torch.randn(batch_size, latent_vector).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def processEpoch(_epoch):\n",
    "    \"\"\"Processes one epoch\"\"\"\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        processBatch(_epoch, data, i) \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = netG(fixed_noise).detach().cpu()\n",
    "          \n",
    "    # Save image\n",
    "    generateImage(_epoch, fake)\n",
    "    \n",
    "    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def processBatch(_epoch, _data, _i):\n",
    "    \"\"\"Processes a batch\"\"\"\n",
    "    \n",
    "    #---\n",
    "    # Train discriminator\n",
    "    #---\n",
    "    \n",
    "    ## Train with batch of real images\n",
    "    \n",
    "    netD.zero_grad()\n",
    "    # Format batch\n",
    "    batch = _data[0].to(device)\n",
    "    batch_size = batch.size(0)\n",
    "    label = torch.full((batch_size,), real_label, device=device)\n",
    "    \n",
    "    # Forward pass real batch through discriminator\n",
    "    output = netD(batch)\n",
    "    \n",
    "    # Calculate loss on all-real batch\n",
    "    errD_real = -output.mean()\n",
    "    \n",
    "    # Calculate gradients for discriminator in backward pass\n",
    "    errD_real.backward()\n",
    "    D_x = output.mean().item()\n",
    "\n",
    "    ## Train with batch of fake images\n",
    "    \n",
    "    # Generate batch of latent vectors\n",
    "    # noise = torch.randn(batch_size, latent_vector, 1, 1, device=device)\n",
    "    noise = Variable(torch.rand(batch_size,latent_vector))\n",
    "    \n",
    "    # Generate fake image batch with generator\n",
    "    fake = netG(noise)\n",
    "    label.fill_(fake_label)\n",
    "    \n",
    "    # Classify all fake batch with discriminator\n",
    "    output = netD(fake.detach()).view(-1)\n",
    "    \n",
    "    # Calculate discriminator's loss on the all-fake batch\n",
    "    errD_fake = output.mean()\n",
    "    \n",
    "    # Calculate the gradients for this batch\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = output.mean().item()\n",
    "    \n",
    "    # Add the gradients from the all-real and all-fake batches\n",
    "    errD = errD_real + errD_fake\n",
    "    \n",
    "    # Update discriminator\n",
    "    optimizerD.step()\n",
    "    \n",
    "    #---\n",
    "    # Train generator\n",
    "    #---\n",
    "    \n",
    "    netG.zero_grad()\n",
    "    label.fill_(real_label)\n",
    "    \n",
    "    # Sicolor_channelse we just updated D, perform another forward pass of all-fake batch through D\n",
    "    output = netD(fake).view(-1)\n",
    "    \n",
    "    # Calculate generator's loss based on this output\n",
    "    errG = criterion(output, label)\n",
    "    \n",
    "    # Calculate gradients for generator\n",
    "    errG.backward()\n",
    "    D_G_z2 = output.mean().item()\n",
    "    \n",
    "    # Update generator\n",
    "    optimizerG.step()\n",
    "    \n",
    "    # ---\n",
    "    # Store results\n",
    "    # ---\n",
    "\n",
    "    # Output training stats\n",
    "    if _i % 10 == 0:\n",
    "        print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "              % (_epoch+1, num_epochs, _i+1, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "    # Save Losses for plotting later\n",
    "    G_losses.append(errG.item())\n",
    "    D_losses.append(errD.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.2 Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    %time processEpoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%capture\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot examples\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}