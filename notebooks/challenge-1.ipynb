{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Applied Programming Coding Challenge #1\n",
    "\n",
    "![title](../img/photo-1533788179956-82e8a027c962.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Original columns\n",
    "col_instant='instant'\n",
    "col_datetime='datetime'\n",
    "col_season='season'\n",
    "col_year='year'\n",
    "col_month='month'\n",
    "col_hour='hour'\n",
    "col_holiday='holiday'\n",
    "col_weekday='weekday'\n",
    "col_workingday='workingday'\n",
    "col_weather_situation='weather_situation'\n",
    "col_temperature='temperature'\n",
    "col_apparent_temperature='apparent_temperature'\n",
    "col_humidity='humidity'\n",
    "col_windspeed='windspeed'\n",
    "\n",
    "# Target columns\n",
    "col_casual='casual'\n",
    "col_registered='registered'\n",
    "col_count='count'\n",
    "\n",
    "# Calculated columns\n",
    "col_temperature_raw='temperature_raw'\n",
    "col_apparent_temperature_raw='apparent_temperature_raw'\n",
    "col_humidity_raw='humidity_raw'\n",
    "col_windspeed_raw='windspeed_raw'\n",
    "col_temperature_raw_rounded='temperature_raw_rounded'\n",
    "\n",
    "col_days_since_start='days_since_start'\n",
    "\n",
    "# Define attribute names\n",
    "attribute_names_day = [col_instant, col_datetime, col_season, col_year, col_month, col_holiday, col_weekday, col_workingday, col_weather_situation,\n",
    "                       col_temperature, col_apparent_temperature, col_humidity, col_windspeed, col_casual, col_registered, col_count]\n",
    "\n",
    "# Read csv files\n",
    "data_bike_day = pd.read_csv(\"../data/bike-sharing-dataset/day.csv\", skiprows=1, names=attribute_names_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Understand data\n",
    "\n",
    "### 2.1 Show basic facts\n",
    "\n",
    "* Show data types of features\n",
    "* Make sure there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_bike_day.info()\n",
    "data_bike_day.isnull().sum()\n",
    "# data_bike_day.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualize raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extreme temperature values\n",
    "temperature_min=-8\n",
    "temperature_max=39\n",
    "# Extreme apparent temperature values\n",
    "apparent_temperature_min=-16\n",
    "apparent_temperature_max=50\n",
    "# Extreme humidity value\n",
    "humidity_max=100\n",
    "# Extreme wind speed value\n",
    "windspeed_max=67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define columns to be one-hot encoded\n",
    "columns_raw_values = [col_temperature_raw, col_apparent_temperature_raw, col_humidity_raw, col_windspeed_raw, col_temperature_raw_rounded]\n",
    "\n",
    "# Restore raw values for day data frame\n",
    "data_bike_day = data_bike_day.assign(temperature_raw=data_bike_day[col_temperature] * (temperature_max-temperature_min) + temperature_min)\n",
    "data_bike_day = data_bike_day.assign(apparent_temperature_raw=data_bike_day[col_apparent_temperature] * (apparent_temperature_max-apparent_temperature_min) + apparent_temperature_min)\n",
    "data_bike_day = data_bike_day.assign(humidity_raw=data_bike_day[col_humidity] * humidity_max)\n",
    "data_bike_day = data_bike_day.assign(windspeed_raw=data_bike_day[col_windspeed] * windspeed_max)\n",
    "\n",
    "# Round values for better visualization\n",
    "data_bike_day = data_bike_day.assign(temperature_raw_rounded=round(data_bike_day[col_temperature_raw]/5,0)*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show first few lines\n",
    "data_bike_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Plot relation between month and number of rented bikes\n",
    "\n",
    "* Make sure data is plausible\n",
    "* Expected plot contains few peaks (most popular biking months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot trend\n",
    "sns.catplot(col_month,col_count,hue=col_year,data=data_bike_day, ci=None, kind='point', palette='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Plot relation between temperature and number of rented bikes\n",
    "\n",
    "* Make sure data is plausible\n",
    "* Expected plot contains one peak (optimal biking temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot trend\n",
    "sns.catplot(col_temperature_raw_rounded,col_count,hue=col_year,data=data_bike_day, ci=None, kind='point', palette='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Plot relation between weather situation and number of rented bikes\n",
    "\n",
    "* Make sure data is plausible\n",
    "* Expected plot indicates that there are significantly more rentals on day having good weather (clear or misty) \n",
    "  * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "  * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "  * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "  * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot trend\n",
    "sns.catplot(col_weather_situation,col_count,hue=col_year,data=data_bike_day, ci=None, kind='strip', palette='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Plot correlation matrix of some attributes\n",
    "\n",
    "* Expected matrix contains the following correlations\n",
    "  * strong correlation between _temperature_ and _apparent temperature_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correlationMatrix=data_bike_day[[col_temperature,col_apparent_temperature,col_humidity,col_windspeed,col_casual,col_registered]].corr()\n",
    "mask=np.array(correlationMatrix)\n",
    "mask[np.tril_indices_from(mask)]=False\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(15,8))\n",
    "sns.heatmap(correlationMatrix,mask=mask,vmax=0.8,square=True,annot=True,ax=ax)\n",
    "ax.set_title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Preprocess data\n",
    "\n",
    "### 3.1 One-hot-encode categorical data\n",
    "\n",
    "* The feature _weekday_ is currently label-encoded which implies an order\n",
    "* The feature _weather_situation_ is currently label-encoded which implies an order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define columns to be one-hot encoded\n",
    "columns_one_hot_encoded = [col_season, col_year, col_month, col_weekday, col_weather_situation]\n",
    "\n",
    "# One-hot encode columns \n",
    "for column in columns_one_hot_encoded:\n",
    "    data_bike_day = pd.concat([data_bike_day,pd.get_dummies(data_bike_day[column], prefix=column)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Enhance data\n",
    "\n",
    "#### 3.2.1 Calculate date since start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate start date\n",
    "# start_date = data_bike_day[col_datetime].min()\n",
    "# data_bike_day[col_days_since_start] = data_bike_day.apply(lambda row: (datetime.datetime.strptime(row[col_datetime], '%Y-%m-%d')-datetime.datetime.strptime(start_date, '%Y-%m-%d')).days, axis = 1) \n",
    "# data_bike_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Drop columns\n",
    "\n",
    "* The following columns need to be dropped\n",
    "  * Indices\n",
    "    * _instant_ since it does not contain any information besides the order\n",
    "  * Columns which cannot be used directly\n",
    "    * _datetime_ which is formatted ```yyyy-mm-dd```\n",
    "  * Columns which are one-hot encoded\n",
    "    * _weekday_\n",
    "    * _weather situation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop index and unusable columns\n",
    "data_bike_day.drop([col_instant],axis=1, inplace=True)\n",
    "data_bike_day.drop([col_datetime],axis=1, inplace=True)\n",
    "\n",
    "# Drop one-hot encoded columns\n",
    "for column in columns_one_hot_encoded:\n",
    "    data_bike_day.drop([column],axis=1, inplace=True)\n",
    "\n",
    "# Drop raw-value columns\n",
    "for column in columns_raw_values:\n",
    "    data_bike_day.drop([column],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Normalize data\n",
    "\n",
    "_tbd_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Split data into _training_ and _test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define columns\n",
    "data_bike_day_x = data_bike_day.drop([col_count, col_casual, col_registered], axis=1)\n",
    "data_bike_day_y = data_bike_day[[col_count]]\n",
    "\n",
    "# Split training data and test data\n",
    "test_size = 0.3\n",
    "random_state = 42\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_bike_day_x, data_bike_day_y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show splitted data\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Put models into dictionary\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(min_samples_split=2,max_leaf_nodes=10),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=200),\n",
    "    \"Lasso\": Lasso(alpha=0.2),\n",
    "    \"Elastic Net\": ElasticNet(alpha=0.2, random_state=42),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Support Vector Regression\": SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Train model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "source": [
    "# Train each model in dictionary\n",
    "for key, value in models.items():\n",
    "    value.fit(x_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model_name, predicted_values, expected_values):\n",
    "    print(model_name)\n",
    "    print(\"explained variance score\", explained_variance_score(expected_values, predicted_values))\n",
    "    print(\"·············· max error\", max_error(expected_values, predicted_values))\n",
    "    print(\"···· mean absolute error\", mean_absolute_error(expected_values, predicted_values))\n",
    "    print(\"····· mean squared error\", mean_squared_error(expected_values, predicted_values))\n",
    "    print(\"· mean squared log error\", mean_squared_log_error(expected_values, predicted_values))\n",
    "    print(\"·· median absolute error\", median_absolute_error(expected_values, predicted_values))\n",
    "    print(\"··············· r2 score\", r2_score(expected_values, predicted_values))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train each model in dictionary\n",
    "for key, value in models.items():\n",
    "    prediction = value.predict(x_test)\n",
    "    evaluateModel(key, prediction, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}